{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/agastyapatel/comparing-different-models-types?scriptVersionId=158048177\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-07T14:55:58.126526Z","iopub.execute_input":"2024-01-07T14:55:58.126804Z","iopub.status.idle":"2024-01-07T14:55:58.137646Z","shell.execute_reply.started":"2024-01-07T14:55:58.126777Z","shell.execute_reply":"2024-01-07T14:55:58.136811Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture \n!pip install nbdev","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:52:30.330607Z","iopub.execute_input":"2024-01-07T14:52:30.331458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Goal\nNotebook tries to compare few model training, explore different training types. We are using high level api 'FastAI' for this purpose. This notebook is based on the quickstart tutorials and tries to explore different models and some training options. Good read for beginners.","metadata":{}},{"cell_type":"markdown","source":"## Computer Vision\nPET CLASSIFIER using [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)\n### About dataset\n- Dataset contains images of cats and dogs\n- Contains data of 37 breeds\n\n**Annotation Methods Used**\n- .trimaps used for providing hints for separation between foreground and background\n- list which provide annotation with index based on categories and filenames\n- Name of the file (If Title case then cat else dog)","metadata":{}},{"cell_type":"code","source":"# Importing Dependency\nfrom fastai.vision.all import *\npetPath = untar_data(URLs.PETS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('BasePath: ',petPath,'\\n', petPath.ls())\nimport os\nos.path.exists(path/'images')","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:52:03.94675Z","iopub.status.idle":"2024-01-07T14:52:03.947133Z","shell.execute_reply.started":"2024-01-07T14:52:03.946957Z","shell.execute_reply":"2024-01-07T14:52:03.946975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = get_image_files(path/'images')\nprint(len(files))   #Number of files\nfiles","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:04:55.098883Z","iopub.execute_input":"2024-01-06T19:04:55.099249Z","iopub.status.idle":"2024-01-06T19:04:55.327588Z","shell.execute_reply.started":"2024-01-06T19:04:55.099214Z","shell.execute_reply":"2024-01-06T19:04:55.326585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_function(f): return 'Cat' if f[0].isupper() else 'Dog'\n\ndls = ImageDataLoaders.from_name_func(path,\n                                      files,\n                                      label_function,\n                                      seed = 0.42,\n                                      valid_pct = 0.2,\n                                      item_tfms=Resize(224))\ndls","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:04:55.328909Z","iopub.execute_input":"2024-01-06T19:04:55.329802Z","iopub.status.idle":"2024-01-06T19:04:56.130449Z","shell.execute_reply.started":"2024-01-06T19:04:55.329766Z","shell.execute_reply":"2024-01-06T19:04:56.129368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:04:56.131821Z","iopub.execute_input":"2024-01-06T19:04:56.13219Z","iopub.status.idle":"2024-01-06T19:04:57.836646Z","shell.execute_reply.started":"2024-01-06T19:04:56.132157Z","shell.execute_reply":"2024-01-06T19:04:57.835573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = vision_learner(dls, resnet34, metrics = error_rate)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:04:57.837668Z","iopub.execute_input":"2024-01-06T19:04:57.837957Z","iopub.status.idle":"2024-01-06T19:04:58.858985Z","shell.execute_reply.started":"2024-01-06T19:04:57.837931Z","shell.execute_reply":"2024-01-06T19:04:58.857975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fine_tune(2)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:04:58.860284Z","iopub.execute_input":"2024-01-06T19:04:58.860657Z","iopub.status.idle":"2024-01-06T19:06:36.563958Z","shell.execute_reply.started":"2024-01-06T19:04:58.860623Z","shell.execute_reply":"2024-01-06T19:06:36.562771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc(learn.show_results)\nlearn.show_results(max_n = 3)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:06:36.568804Z","iopub.execute_input":"2024-01-06T19:06:36.569122Z","iopub.status.idle":"2024-01-06T19:06:38.498991Z","shell.execute_reply.started":"2024-01-06T19:06:36.569085Z","shell.execute_reply":"2024-01-06T19:06:38.497786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing other pretrained model\nWe will be using resnet18 and convnext for comparision","metadata":{}},{"cell_type":"code","source":"!pip show timm","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:06:38.50037Z","iopub.execute_input":"2024-01-06T19:06:38.500805Z","iopub.status.idle":"2024-01-06T19:06:50.453532Z","shell.execute_reply.started":"2024-01-06T19:06:38.500765Z","shell.execute_reply":"2024-01-06T19:06:50.452357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\ntimm.list_models('convnext*') # Prints available model","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:06:50.455098Z","iopub.execute_input":"2024-01-06T19:06:50.45545Z","iopub.status.idle":"2024-01-06T19:06:50.46426Z","shell.execute_reply.started":"2024-01-06T19:06:50.45541Z","shell.execute_reply":"2024-01-06T19:06:50.463245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn18 = vision_learner(dls, resnet18, metrics = error_rate)\nlearn18.fine_tune(2)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:06:50.465489Z","iopub.execute_input":"2024-01-06T19:06:50.465825Z","iopub.status.idle":"2024-01-06T19:08:12.091317Z","shell.execute_reply.started":"2024-01-06T19:06:50.465796Z","shell.execute_reply":"2024-01-06T19:08:12.090233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learnCon = vision_learner(dls, 'convnext_nano', metrics = error_rate)\nlearnCon.fine_tune(2)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:08:12.093024Z","iopub.execute_input":"2024-01-06T19:08:12.093434Z","iopub.status.idle":"2024-01-06T19:11:05.267022Z","shell.execute_reply.started":"2024-01-06T19:08:12.093392Z","shell.execute_reply":"2024-01-06T19:11:05.265723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learnCon.show_results(max_n = 3)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:11:05.268646Z","iopub.execute_input":"2024-01-06T19:11:05.268993Z","iopub.status.idle":"2024-01-06T19:11:06.619302Z","shell.execute_reply.started":"2024-01-06T19:11:05.268958Z","shell.execute_reply":"2024-01-06T19:11:06.618423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compared different models\n- Resnet 34 \n- Resnet 18\n- ConvNext_Nano\n\nOutcome:\nWhile considering model, following things can be a factor which can be considered : \n- size of the model: Whether the model will fit in gpu while fine tuning?\n- Smaller model or less layered Nueral network will be quicker to train but accuracy will be compromised.\n- In circumstances where accuracy is primary factor and predication are made extremely critical situation; then more accurate model should be preferred.","metadata":{}},{"cell_type":"markdown","source":"## Train Breed Identifier\nWe will be using from_name_re (identifies label from path using re)","metadata":{}},{"cell_type":"code","source":"print(files[0].name)\nre = r'^(.*)_\\d+.jpg'\nbreedDls = ImageDataLoaders.from_name_re(path,\n                              files,\n                              re, item_tfms = Resize(224))\nbreedDls.show_batch(max_n = 3)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:19:08.365549Z","iopub.execute_input":"2024-01-06T19:19:08.36656Z","iopub.status.idle":"2024-01-06T19:19:09.78615Z","shell.execute_reply.started":"2024-01-06T19:19:08.366505Z","shell.execute_reply":"2024-01-06T19:19:09.785066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breedLearner = vision_learner(breedDls, resnet34, metrics = error_rate)       ","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:19:10.763318Z","iopub.execute_input":"2024-01-06T19:19:10.764266Z","iopub.status.idle":"2024-01-06T19:19:11.219801Z","shell.execute_reply.started":"2024-01-06T19:19:10.76423Z","shell.execute_reply":"2024-01-06T19:19:11.218762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breedLearner.fine_tune(2)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:19:15.416711Z","iopub.execute_input":"2024-01-06T19:19:15.417481Z","iopub.status.idle":"2024-01-06T19:20:59.41795Z","shell.execute_reply.started":"2024-01-06T19:19:15.417443Z","shell.execute_reply":"2024-01-06T19:20:59.416879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Breed Learner2 Contains the learning rate suggested by learning rate finder\nbreedDls = ImageDataLoaders.from_name_re(path,\n                              files,\n                              re, item_tfms = Resize(224))\nbreedLearner2 = vision_learner(breedDls, resnet34, metrics = error_rate)\nlr = breedLearner2.lr_find(suggest_funcs=(minimum, steep, valley, slide)) ","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:31:29.251885Z","iopub.execute_input":"2024-01-06T19:31:29.252405Z","iopub.status.idle":"2024-01-06T19:31:53.938097Z","shell.execute_reply.started":"2024-01-06T19:31:29.252364Z","shell.execute_reply":"2024-01-06T19:31:53.936851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breedLearner2.fine_tune(2, lr.slide)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:32:01.425319Z","iopub.execute_input":"2024-01-06T19:32:01.42572Z","iopub.status.idle":"2024-01-06T19:33:42.320727Z","shell.execute_reply.started":"2024-01-06T19:32:01.425677Z","shell.execute_reply":"2024-01-06T19:33:42.319588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Resnet34 with Learning Rate Performance\nResnet34 with good learning rate is more accurate when trained for same epochs.","metadata":{}},{"cell_type":"code","source":"breedLearner2.show_results()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:35:47.906673Z","iopub.execute_input":"2024-01-06T19:35:47.907104Z","iopub.status.idle":"2024-01-06T19:35:49.767401Z","shell.execute_reply.started":"2024-01-06T19:35:47.907057Z","shell.execute_reply":"2024-01-06T19:35:49.766364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = Interpretation.from_learner(breedLearner2)\ninterp.plot_top_losses(9, figsize = (15,10))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:35:56.660436Z","iopub.execute_input":"2024-01-06T19:35:56.660857Z","iopub.status.idle":"2024-01-06T19:36:04.852201Z","shell.execute_reply.started":"2024-01-06T19:35:56.660816Z","shell.execute_reply":"2024-01-06T19:36:04.851156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classInterp = ClassificationInterpretation.from_learner(breedLearner2)\nclassInterp.plot_confusion_matrix(figsize=(12,12), dpi=60)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:36:04.853481Z","iopub.execute_input":"2024-01-06T19:36:04.853817Z","iopub.status.idle":"2024-01-06T19:36:19.667525Z","shell.execute_reply.started":"2024-01-06T19:36:04.853786Z","shell.execute_reply":"2024-01-06T19:36:19.666495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Single Label Classification\nUsing Datablock API. These type of classification is used to make single prediction ie, the class of the object.","metadata":{}},{"cell_type":"code","source":"pets = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                splitter = RandomSplitter(),\n                get_y = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n                item_tfms = Resize(460),\n                batch_tfms = aug_transforms(size=224))\ndls2 = pets.dataloaders(untar_data(URLs.PETS)/'images')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:17:10.537038Z","iopub.execute_input":"2024-01-06T19:17:10.537416Z","iopub.status.idle":"2024-01-06T19:17:11.330942Z","shell.execute_reply.started":"2024-01-06T19:17:10.537375Z","shell.execute_reply":"2024-01-06T19:17:11.329868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch(max_n = 9)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T19:17:11.395465Z","iopub.execute_input":"2024-01-06T19:17:11.395781Z","iopub.status.idle":"2024-01-06T19:17:13.074154Z","shell.execute_reply.started":"2024-01-06T19:17:11.395754Z","shell.execute_reply":"2024-01-06T19:17:13.072939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-Label Classification\nClassifier for not only guessing the class of the object but also to draw an bounding box around the object recognized.\n### About Dataset\nName: Pascal 2007\n[Reference](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/)\\\nGoal: To guess the class of the object and also to draw a visual bounding box around the object.\nClasses Determined:\n- Person: person\n- Animal: bird, cat, cow, dog, horse, sheep\n- Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train\n- Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor","metadata":{}},{"cell_type":"code","source":"# Downloading data set\nmlcPath = untar_data(URLs.PASCAL_2007, base='/kaggle/temp/')\nprint(mlcPath/'train.csv')\nmlcPath.ls()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:02:18.842989Z","iopub.execute_input":"2024-01-06T20:02:18.843344Z","iopub.status.idle":"2024-01-06T20:02:18.852022Z","shell.execute_reply.started":"2024-01-06T20:02:18.843313Z","shell.execute_reply":"2024-01-06T20:02:18.851029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(mlcPath/'train.csv')\nprint(type(df))\ndf","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:02:20.955874Z","iopub.execute_input":"2024-01-06T20:02:20.956829Z","iopub.status.idle":"2024-01-06T20:02:20.976856Z","shell.execute_reply.started":"2024-01-06T20:02:20.956782Z","shell.execute_reply":"2024-01-06T20:02:20.975806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls = ImageDataLoaders.from_df(df, mlcPath, folder='train', valid_col='is_valid', label_delim=' ',\n                               item_tfms=Resize(460), batch_tfms=aug_transforms(size=224))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:02:23.271236Z","iopub.execute_input":"2024-01-06T20:02:23.271616Z","iopub.status.idle":"2024-01-06T20:02:23.557062Z","shell.execute_reply.started":"2024-01-06T20:02:23.271581Z","shell.execute_reply":"2024-01-06T20:02:23.556094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:02:45.784632Z","iopub.execute_input":"2024-01-06T20:02:45.78499Z","iopub.status.idle":"2024-01-06T20:02:48.0825Z","shell.execute_reply.started":"2024-01-06T20:02:45.784961Z","shell.execute_reply":"2024-01-06T20:02:48.081486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_macro = F1ScoreMulti(thresh=0.5, average='macro')\nf1_macro.name = 'F1(macro)'\nf1_samples = F1ScoreMulti(thresh=0.5, average='samples')\nf1_samples.name = 'F1(samples)'\nlearn = vision_learner(dls, resnet50, metrics=[partial(accuracy_multi, thresh=0.5), f1_macro, f1_samples])","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:03:49.673052Z","iopub.execute_input":"2024-01-06T20:03:49.674018Z","iopub.status.idle":"2024-01-06T20:03:50.776224Z","shell.execute_reply.started":"2024-01-06T20:03:49.673973Z","shell.execute_reply":"2024-01-06T20:03:50.775251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = learn.lr_find(suggest_funcs = (minimum, slide))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:05:56.509569Z","iopub.execute_input":"2024-01-06T20:05:56.509988Z","iopub.status.idle":"2024-01-06T20:06:51.419746Z","shell.execute_reply.started":"2024-01-06T20:05:56.509952Z","shell.execute_reply":"2024-01-06T20:06:51.418696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fine_tune(2, lr.slide)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:06:51.45764Z","iopub.execute_input":"2024-01-06T20:06:51.457906Z","iopub.status.idle":"2024-01-06T20:08:50.984026Z","shell.execute_reply.started":"2024-01-06T20:06:51.457878Z","shell.execute_reply":"2024-01-06T20:08:50.98295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.predict(mlcPath/'train/000005.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:09:40.833496Z","iopub.execute_input":"2024-01-06T20:09:40.833896Z","iopub.status.idle":"2024-01-06T20:09:40.969246Z","shell.execute_reply.started":"2024-01-06T20:09:40.833864Z","shell.execute_reply":"2024-01-06T20:09:40.968328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = Interpretation.from_learner(learn)\ninterp.plot_top_losses(9)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T20:09:51.864387Z","iopub.execute_input":"2024-01-06T20:09:51.865347Z","iopub.status.idle":"2024-01-06T20:10:07.375364Z","shell.execute_reply.started":"2024-01-06T20:09:51.865303Z","shell.execute_reply":"2024-01-06T20:10:07.374071Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
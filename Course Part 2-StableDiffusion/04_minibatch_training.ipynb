{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a90a4cb-ac18-4ac0-815e-05a1436e6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82b0b309-14f7-4415-b901-2fa1ab156636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52fbabd8-9b9b-4704-9864-af9c954a208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d16ec68-c247-4efa-9cc2-65fb0a462411",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6b603-241a-4e5c-b76a-e8ea1b82e6d6",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3d55a76-15ee-491c-97ca-33d52ee38cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1221dcd-1d30-47d3-bc9e-511d4b43d9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10), 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh=50\n",
    "n,m,c, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "743a82ae-9130-4ad0-b0c1-5306b1ff84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9eb4bfb9-76e0-4648-b73d-9a51a710f4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.09, -0.21, -0.08,  ..., -0.03,  0.01,  0.06],\n",
       "        [-0.07, -0.14, -0.14,  ...,  0.03,  0.04,  0.14],\n",
       "        [-0.19, -0.04,  0.02,  ..., -0.01, -0.00,  0.02],\n",
       "        ...,\n",
       "        [-0.03, -0.22, -0.04,  ..., -0.01,  0.09,  0.14],\n",
       "        [-0.10, -0.09, -0.05,  ..., -0.01,  0.02,  0.11],\n",
       "        [-0.03, -0.25, -0.06,  ...,  0.00,  0.03,  0.14]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "516cb400-0303-4cca-bf92-da44f8d5f496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "623b63b1-a7fe-4ec8-9b57-39023bd2a618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9dbb3fe-7608-4f94-b509-dd55fffeb443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0da918b-0f67-4d7c-8b24-e88a28751a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
       "        3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fb861dd-2419-4f1b-95de-75930efbb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b7aacb0-c056-453b-a2fb-06593d21d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "302c60a7-1a46-4a0e-8904-97d5f9aa5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f10aa5fb-8f61-489f-b6b1-ef75d4e3a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1c09602-1540-4450-b87c-11d1839ccac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.12, 0.94\n",
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc0b11-ca0a-4c06-b793-ffc01135e630",
   "metadata": {},
   "source": [
    "## Using parameters and Optim\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7c9399e-81b2-4e7c-9949-066464df8793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1fab30f-56d1-4f2d-a5fe-c9c7d3282108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.named_children at 0x7ff6e9e153f0>,\n",
       " [('foo', Linear(in_features=3, out_features=4, bias=True))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children(), list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c67063e5-4872-4898-8141-18b2f7a803e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0643ed5-b603-4051-827e-dd0a6df2d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31465bb6-9f24-4107-9fd1-d8cd9744278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43d283fb-02e6-4701-92a2-9d0424e08e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3ff1df4-ad20-40f5-afa5-62536000de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f'{name}: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c09f858-3a60-4a0f-9239-542127d5b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79320369-62b2-4153-adfb-bc8d61802cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70257727-49e5-4f7c-b6a7-d0a428afa247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, 0.96\n",
      "0.11, 0.96\n",
      "0.04, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27d436-602c-428b-8120-24f69c87e31b",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68d6320e-8378-4fc9-b7fd-3acb6c469425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()     # [Equivalent] for p in l.parameters: yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65ccb555-7bd6-4a97-b024-566d75975d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa340a07-2fe6-4dc5-8d73-b6860fa9fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74eabb-2959-4a00-afd2-18b735008e85",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa3fee44-a24e-4446-b387-3f87d58f25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2baac-0f39-4a86-b433-eb8e6f31f815",
   "metadata": {},
   "source": [
    "We can use the orignal `layers` approach, byt we have to register the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85fc0277-1f84-40df-aad0-24c3c0f8574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c4787e0-5716-4835-81ed-45ffe8a7e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        # add__module method is used for making pytorch acknowledge the layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "\n",
    "    def forward(self, x): return reduce(lambda val,layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a5b2779-6ff8-4298-9206-ef404bf4d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13970a04-5c89-4adc-b7e2-d6570964d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9733769-db10-4d3e-8606-f58662f6aadf",
   "metadata": {},
   "source": [
    "## nn.ModuleList\n",
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c5f92b4-c17c-4245-bc5d-36eebe21a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        # Module list performs add_module method over list of layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58fe934d-0d1c-478f-aa64-35624e446fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3eb1d42d-863a-4282-a95a-ec729d827478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.11, 0.96\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a26a9-ba3d-4735-8d1f-e0484391fb43",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "It is a pytorch class which performs the above feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f23fa6fb-2c93-46c3-b2c8-c50645ab58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bbc096a-6760-400c-a166-d6ecd74fe758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15, 0.96\n",
      "0.11, 0.96\n",
      "0.09, 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07f6d754-744f-48e8-98cb-206ca067eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd483273-0e51-4e7c-b382-fec845ae4d7c",
   "metadata": {},
   "source": [
    "## optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd601336-9cb6-4ec8-90e5-849a1ddbd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params, self.lr = list(params), lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7d03a77-c11a-4eae-8713-64f6dfc25554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97cacc5f-910e-4c53-87a0-27b766f3b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae523ab9-0ccb-4bbf-a0aa-e03ff9314bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11eb0f8d-b3e9-42c8-8946-4504a3d02e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18, 0.94\n",
      "0.13, 0.96\n",
      "0.11, 0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f63d43-4946-471f-ae48-140f5230b4f6",
   "metadata": {},
   "source": [
    "Pytorch provides exact same functionality with optim.SGD. It also handles momentum which we'll look later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bc607fb-a813-490e-808f-5f834f5195e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a0629d6-664c-488d-b736-e8b36c1546fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfccbc2b-5f4a-4574-b8a3-dc9b40e4723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.33, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "504f4158-4275-42c1-a809-97b20e0eec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.09, 0.98\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757f303-defb-420e-8b66-587e3e930e73",
   "metadata": {},
   "source": [
    "### Dataset & Dataloaders\n",
    "Dataset\n",
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "Instead, let's do these two steps together, by introducing a Dataset class:\n",
    "\n",
    "xb,yb = train_ds[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31812098-7f85-4e30-8d67-60d77a94c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5672930-89e9-4321-94b6-1dcfe033f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b70ef3eb-278a-4711-a9e4-42f22073bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6f9f335-22b1-437b-b21c-ecf4caeb597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2d9e050-59f6-46b9-8261-99243d73b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17, 0.96\n",
      "0.11, 0.94\n",
      "0.09, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = train_ds[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c61c6-8faa-4230-9159-b893a632e3fc",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "```python\n",
    "for i in range(0, n, bs):\n",
    "    xb,yb = train_ds[i:min(n,i+bs)]\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's make our loop much cleaner, using a data loader:\\n,\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3bf8cd1-97e5-47e3-9507-4a8597307107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i: i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd21f796-8721-438a-9471-798baa28afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2724632b-6242-4b11-a208-7654a25a6081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cca8807a-c5da-44c0-97b7-b7ee06d54f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35720e36-4d0c-4544-989b-c00defa82109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d39ea990-47fe-4cf1-8676-449a3aef1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc196b8c-00e7-41e6-a6f6-cdb3fb41f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.98\n",
      "0.09, 0.98\n",
      "0.06, 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.16, grad_fn=<NllLossBackward0>), tensor(0.96))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f10f6-a70f-45bb-8902-1f16ed523495",
   "metadata": {},
   "source": [
    "## Random Sampling \n",
    "We want our training set to be in a random order, and that order should be differ each iteraction. But the validation set shouldn't be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e9152ad-e17c-4195-a091-3d971f86ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11de5378-5512-49f9-91e4-d0ef16837d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4e52835a-577f-4bc1-a067-c2656a922f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1c7175d7-888b-43c7-af59-ba2cd3e30dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9428daa7-ddd6-4a58-8ef5-f4af21d38a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for o in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e48e9b2-6a3d-4f4f-8310-af57cdcd5635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87304903-d3db-46cf-9c95-fa2977315678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41554, 19682, 10787, 11193, 30099]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c29df93e-ee79-4e12-888e-467eafcd531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1d76ed7-36fd-4e7d-ae79-e11eb3b53d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b943e4d-3d2a-4d95-9346-e8243220db1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40580, 39180, 6291, 29255],\n",
       " [15881, 1728, 26265, 37711],\n",
       " [49313, 49347, 10033, 31788],\n",
       " [20141, 20206, 10762, 36560],\n",
       " [46755, 18048, 38495, 42600]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfb18c03-fa3e-4a66-9352-bcb7cce45c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aee266e8-4102-4749-987a-b8722c854ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cdb182d0-0f1d-4fda-b273-8c8a20f87fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "075c5460-57da-4a55-b69c-654411df8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cdad8c0e-b71a-4c33-ac77-27b0f65f76a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZm0lEQVR4nO3df2hV9/3H8df11/XHbi4TTe69M+YbRFfXiKPq1OBvMDMwt5huaAslQmfbVYUsLW5OhqED0znM9kemY2XYSrUThrUO3TRDE1tctlTsFOskxTgzTJop9d6Y2hvUz/cP8dLb2Oi53us7N3k+4IL33vP2fnp25tPjvffE55xzAgDAwBDrBQAABi8iBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzAyzXsAX3b59W5cvX1YgEJDP57NeDgDAI+ecurq6FIlENGRI3+c6/S5Cly9fVn5+vvUyAAAPqa2tTRMmTOhzm373z3GBQMB6CQCANHiQP88zFqHt27ersLBQI0eO1IwZM/Tuu+8+0Bz/BAcAA8OD/HmekQjt3btXlZWV2rRpk06dOqX58+ertLRUly5dysTLAQCylC8TV9GePXu2nnjiCe3YsSPx2NSpU1VWVqaampo+Z2OxmILBYLqXBAB4xKLRqHJycvrcJu1nQj09PTp58qRKSkqSHi8pKdGJEyd6bR+PxxWLxZJuAIDBIe0RunLlim7duqW8vLykx/Py8tTR0dFr+5qaGgWDwcSNT8YBwOCRsQ8mfPENKefcPd+k2rhxo6LRaOLW1taWqSUBAPqZtH9PaNy4cRo6dGivs57Ozs5eZ0eS5Pf75ff7070MAEAWSPuZ0IgRIzRjxgzV19cnPV5fX6/i4uJ0vxwAIItl5IoJVVVVeuaZZzRz5kzNnTtXv//973Xp0iW98MILmXg5AECWykiEVq5cqatXr+qVV15Re3u7ioqKdOjQIRUUFGTi5QAAWSoj3xN6GHxPCAAGBpPvCQEA8KCIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZtEeourpaPp8v6RYKhdL9MgCAAWBYJn7Txx9/XH/7298S94cOHZqJlwEAZLmMRGjYsGGc/QAA7isj7wm1tLQoEomosLBQq1at0oULF75023g8rlgslnQDAAwOaY/Q7NmztWvXLh0+fFivvfaaOjo6VFxcrKtXr95z+5qaGgWDwcQtPz8/3UsCAPRTPuecy+QLdHd3a9KkSdqwYYOqqqp6PR+PxxWPxxP3Y7EYIQKAASAajSonJ6fPbTLyntDnjRkzRtOmTVNLS8s9n/f7/fL7/ZleBgCgH8r494Ti8bjOnTuncDic6ZcCAGSZtEfo5ZdfVmNjo1pbW/WPf/xD3//+9xWLxVRRUZHulwIAZLm0/3Pcf//7Xz311FO6cuWKxo8frzlz5qipqUkFBQXpfikAQJbL+AcTvIrFYgoGg9bLAB7Y+fPnPc/861//8jzz3HPPeZ65du2a5xkgXR7kgwlcOw4AYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMJPxH2oHDHRr1qzxPPPnP//Z88yVK1c8z3R3d3uekaQDBw54nmloaPA8c/nyZc8zf/nLXzzPoP/iTAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmfM45Z72Iz4vFYgoGg9bLADLqmWee8TyzatWqDKwkfebMmeN55qtf/arnmXfeecfzzIoVKzzP4OFFo1Hl5OT0uQ1nQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGS5gCiAtRo8e7XnmlVde8TxTVVXleWbZsmWeZyTpyJEjKc3hDi5gCgDo14gQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM8OsFwBgYLh586bnmfnz53ueuXXrlueZaDTqeQaPBmdCAAAzRAgAYMZzhI4fP67ly5crEonI5/Np//79Sc8751RdXa1IJKJRo0Zp0aJFOnv2bLrWCwAYQDxHqLu7W9OnT1ddXd09n9+6datqa2tVV1en5uZmhUIhLV26VF1dXQ+9WADAwOL5gwmlpaUqLS2953POOf3mN7/Rpk2bVF5eLkl64403lJeXpz179uj5559/uNUCAAaUtL4n1Nraqo6ODpWUlCQe8/v9WrhwoU6cOHHPmXg8rlgslnQDAAwOaY1QR0eHJCkvLy/p8by8vMRzX1RTU6NgMJi45efnp3NJAIB+LCOfjvP5fEn3nXO9Hrtr48aNikajiVtbW1smlgQA6IfS+mXVUCgk6c4ZUTgcTjze2dnZ6+zoLr/fL7/fn85lAACyRFrPhAoLCxUKhVRfX594rKenR42NjSouLk7nSwEABgDPZ0LXr1/XRx99lLjf2tqqDz74QGPHjtXEiRNVWVmpLVu2aPLkyZo8ebK2bNmi0aNH6+mnn07rwgEA2c9zhN5//30tXrw4cb+qqkqSVFFRoddff10bNmzQjRs39OKLL+qTTz7R7NmzdeTIEQUCgfStGgAwIPicc856EZ8Xi8UUDAatlwEManPmzPE8s3PnTs8zkyZN8jzz3HPPeZ55/fXXPc/g4UWjUeXk5PS5DdeOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJm0/mRVAA9mwoQJnmd++MMfep558sknPc9I0v/93/95nnnrrbc8z3z+x8I8qI6ODs8z6L84EwIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHABUwxIY8aMSWlu6tSpnmdWrVrleSaVi5H++9//9jyza9cuzzOSdPjwYc8zp0+fTum1MLhxJgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOECptCzzz6b0tykSZM8z5SVlXme8fv9nmdu3brleUaSuru7Pc8cOnTI88yiRYs8z5w7d87zTDwe9zwDPEqcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriAKfTrX/86pbmvfOUrnmd8Pp/nGeec55lUL9y5fft2zzOpXCz1scce8zzT3t7ueebjjz/2PAM8SpwJAQDMECEAgBnPETp+/LiWL1+uSCQin8+n/fv3Jz2/evVq+Xy+pNucOXPStV4AwADiOULd3d2aPn266urqvnSbZcuWqb29PXFL5Yd+AQAGPs8fTCgtLVVpaWmf2/j9foVCoZQXBQAYHDLynlBDQ4Nyc3M1ZcoUrVmzRp2dnV+6bTweVywWS7oBAAaHtEeotLRUu3fv1tGjR7Vt2zY1NzdryZIlX/qR2ZqaGgWDwcQtPz8/3UsCAPRTaf+e0MqVKxO/Lioq0syZM1VQUKCDBw+qvLy81/YbN25UVVVV4n4sFiNEADBIZPzLquFwWAUFBWppabnn836/X36/P9PLAAD0Qxn/ntDVq1fV1tamcDic6ZcCAGQZz2dC169f10cffZS439raqg8++EBjx47V2LFjVV1drSeffFLhcFgXL17Uz372M40bN04rVqxI68IBANnPc4Tef/99LV68OHH/7vs5FRUV2rFjh86cOaNdu3bp2rVrCofDWrx4sfbu3atAIJC+VQMABgSfS+XqkBkUi8UUDAatlzGopHIxTUkaOnRomldyb9/97nc9z4wcOTIDK0mfZcuWeZ6JRCKeZ37wgx94npGkpqamlOaAz4tGo8rJyelzG64dBwAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNcRRvIEnv27PE8M23atJRea9asWZ5nPvvss5ReCwMXV9EGAPRrRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZYdYLAPBgamtrPc/885//TOm1vvnNb3qeaWpqSum1MLhxJgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOECpkCWGD9+vPUSgLTjTAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMFTIEsUVVV5Xnm448/Tum1Pvzww5TmAK84EwIAmCFCAAAzniJUU1OjWbNmKRAIKDc3V2VlZTp//nzSNs45VVdXKxKJaNSoUVq0aJHOnj2b1kUDAAYGTxFqbGzU2rVr1dTUpPr6et28eVMlJSXq7u5ObLN161bV1taqrq5Ozc3NCoVCWrp0qbq6utK+eABAdvM551yqw//73/+Um5urxsZGLViwQM45RSIRVVZW6ic/+YkkKR6PKy8vT7/85S/1/PPP3/f3jMViCgaDqS4JGLDq6+s9zxQVFaX0Wl//+tc9z8RisZReCwNXNBpVTk5On9s81HtC0WhUkjR27FhJUmtrqzo6OlRSUpLYxu/3a+HChTpx4sQ9f494PK5YLJZ0AwAMDilHyDmnqqoqzZs3L/G3rY6ODklSXl5e0rZ5eXmJ576opqZGwWAwccvPz091SQCALJNyhNatW6fTp0/rrbfe6vWcz+dLuu+c6/XYXRs3blQ0Gk3c2traUl0SACDLpPRl1fXr1+vAgQM6fvy4JkyYkHg8FApJunNGFA6HE493dnb2Oju6y+/3y+/3p7IMAECW83Qm5JzTunXrtG/fPh09elSFhYVJzxcWFioUCiW9gdrT06PGxkYVFxenZ8UAgAHD05nQ2rVrtWfPHr3zzjsKBAKJ93mCwaBGjRoln8+nyspKbdmyRZMnT9bkyZO1ZcsWjR49Wk8//XRG/gMAANnLU4R27NghSVq0aFHS4zt37tTq1aslSRs2bNCNGzf04osv6pNPPtHs2bN15MgRBQKBtCwYADBwPNT3hDKB7wlhMPj2t7/teeZPf/qT55mtW7d6npGkX/ziFynNAZ+X8e8JAQDwMIgQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGq2gDDykSiXieaW5u9jxz8+ZNzzPTpk3zPCPd+f8h8LC4ijYAoF8jQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwMs14AkAlDhqT296tnn33W80xtba3nmRs3bnieKS8v9zzDhUjR33EmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QKm6Pd8Pp/nmR//+McpvdavfvUrzzNvvvmm55m1a9d6nunq6vI8A/R3nAkBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4gOkAM3HiRM8zPT09Kb3W1KlTPc8cO3bM88zPf/5zzzPf+MY3PM9IUllZmeeZAwcOpPRaADgTAgAYIkIAADOeIlRTU6NZs2YpEAgoNzdXZWVlOn/+fNI2q1evls/nS7rNmTMnrYsGAAwMniLU2NiotWvXqqmpSfX19bp586ZKSkrU3d2dtN2yZcvU3t6euB06dCitiwYADAyePpjw17/+Nen+zp07lZubq5MnT2rBggWJx/1+v0KhUHpWCAAYsB7qPaFoNCpJGjt2bNLjDQ0Nys3N1ZQpU7RmzRp1dnZ+6e8Rj8cVi8WSbgCAwSHlCDnnVFVVpXnz5qmoqCjxeGlpqXbv3q2jR49q27Ztam5u1pIlSxSPx+/5+9TU1CgYDCZu+fn5qS4JAJBlUv6e0Lp163T69Gm99957SY+vXLky8euioiLNnDlTBQUFOnjwoMrLy3v9Phs3blRVVVXifiwWI0QAMEikFKH169frwIEDOn78uCZMmNDntuFwWAUFBWppabnn836/X36/P5VlAACynKcIOee0fv16vf3222poaFBhYeF9Z65evaq2tjaFw+GUFwkAGJg8vSe0du1avfnmm9qzZ48CgYA6OjrU0dGhGzduSJKuX7+ul19+WX//+9918eJFNTQ0aPny5Ro3bpxWrFiRkf8AAED28nQmtGPHDknSokWLkh7fuXOnVq9eraFDh+rMmTPatWuXrl27pnA4rMWLF2vv3r0KBAJpWzQAYGDw/M9xfRk1apQOHz78UAsCAAwePne/sjxisVhMwWDQehkAgIcUjUaVk5PT5zZcwBQAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz/S5CzjnrJQAA0uBB/jzvdxHq6uqyXgIAIA0e5M9zn+tnpx63b9/W5cuXFQgE5PP5kp6LxWLKz89XW1ubcnJyjFZoj/1wB/vhDvbDHeyHO/rDfnDOqaurS5FIREOG9H2uM+wRremBDRkyRBMmTOhzm5ycnEF9kN3FfriD/XAH++EO9sMd1vshGAw+0Hb97p/jAACDBxECAJjJqgj5/X5t3rxZfr/feimm2A93sB/uYD/cwX64I9v2Q7/7YAIAYPDIqjMhAMDAQoQAAGaIEADADBECAJjJqght375dhYWFGjlypGbMmKF3333XekmPVHV1tXw+X9ItFApZLyvjjh8/ruXLlysSicjn82n//v1JzzvnVF1drUgkolGjRmnRokU6e/aszWIz6H77YfXq1b2Ojzlz5tgsNkNqamo0a9YsBQIB5ebmqqysTOfPn0/aZjAcDw+yH7LleMiaCO3du1eVlZXatGmTTp06pfnz56u0tFSXLl2yXtoj9fjjj6u9vT1xO3PmjPWSMq67u1vTp09XXV3dPZ/funWramtrVVdXp+bmZoVCIS1dunTAXYfwfvtBkpYtW5Z0fBw6dOgRrjDzGhsbtXbtWjU1Nam+vl43b95USUmJuru7E9sMhuPhQfaDlCXHg8sS3/rWt9wLL7yQ9Nhjjz3mfvrTnxqt6NHbvHmzmz59uvUyTElyb7/9duL+7du3XSgUcq+++mrisc8++8wFg0H3u9/9zmCFj8YX94NzzlVUVLjvfe97Juux0tnZ6SS5xsZG59zgPR6+uB+cy57jISvOhHp6enTy5EmVlJQkPV5SUqITJ04YrcpGS0uLIpGICgsLtWrVKl24cMF6SaZaW1vV0dGRdGz4/X4tXLhw0B0bktTQ0KDc3FxNmTJFa9asUWdnp/WSMioajUqSxo4dK2nwHg9f3A93ZcPxkBURunLlim7duqW8vLykx/Py8tTR0WG0qkdv9uzZ2rVrlw4fPqzXXntNHR0dKi4u1tWrV62XZubu//6D/diQpNLSUu3evVtHjx7Vtm3b1NzcrCVLligej1svLSOcc6qqqtK8efNUVFQkaXAeD/faD1L2HA/97iraffnij3ZwzvV6bCArLS1N/HratGmaO3euJk2apDfeeENVVVWGK7M32I8NSVq5cmXi10VFRZo5c6YKCgp08OBBlZeXG64sM9atW6fTp0/rvffe6/XcYDoevmw/ZMvxkBVnQuPGjdPQoUN7/U2ms7Oz1994BpMxY8Zo2rRpamlpsV6KmbufDuTY6C0cDqugoGBAHh/r16/XgQMHdOzYsaQf/TLYjocv2w/30l+Ph6yI0IgRIzRjxgzV19cnPV5fX6/i4mKjVdmLx+M6d+6cwuGw9VLMFBYWKhQKJR0bPT09amxsHNTHhiRdvXpVbW1tA+r4cM5p3bp12rdvn44eParCwsKk5wfL8XC//XAv/fZ4MPxQhCd//OMf3fDhw90f/vAH9+GHH7rKyko3ZswYd/HiReulPTIvvfSSa2hocBcuXHBNTU3uO9/5jgsEAgN+H3R1dblTp065U6dOOUmutrbWnTp1yv3nP/9xzjn36quvumAw6Pbt2+fOnDnjnnrqKRcOh10sFjNeeXr1tR+6urrcSy+95E6cOOFaW1vdsWPH3Ny5c93Xvva1AbUffvSjH7lgMOgaGhpce3t74vbpp58mthkMx8P99kM2HQ9ZEyHnnPvtb3/rCgoK3IgRI9wTTzyR9HHEwWDlypUuHA674cOHu0gk4srLy93Zs2etl5Vxx44dc5J63SoqKpxzdz6Wu3nzZhcKhZzf73cLFixwZ86csV10BvS1Hz799FNXUlLixo8f74YPH+4mTpzoKioq3KVLl6yXnVb3+u+X5Hbu3JnYZjAcD/fbD9l0PPCjHAAAZrLiPSEAwMBEhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJj5f98v3MMaDbRmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e7e6efca-432c-4577-805c-f351278bb754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b77e7aab-c959-449d-8e9b-4a2e96153ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.05, 1.00\n",
      "0.02, 1.00\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e76f2-67b4-4b9d-8885-dbf1947b215b",
   "metadata": {},
   "source": [
    "## Multiprocessing Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8f6ed588-fec6-4daa-9eed-43057c323e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "59583268-e155-44d3-809c-8e50a5c81519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b90b4288-77cc-420b-a5a8-dfd9bab30098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "df12d249-50c7-43eb-9554-464cdc8e8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "babbd36c-c98d-4eac-9dc3-6a85d79e69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex:\n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "880a337d-9041-450b-b0bb-fa38b22e2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7ff6fab-11a7-471c-8520-e50845daddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb= next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b5272-4d84-4403-8841-a70f3bcecefd",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b282e281-4fb8-409b-b7bd-eef27d294915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b94bf28c-dc00-4839-838c-32e17a618b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4d0bd169-4393-4490-8c45-289c807ad832",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn = collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3301d6ef-8905-4ebb-a0f4-10f835038b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.96\n",
      "0.11, 0.96\n",
      "0.25, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.06, grad_fn=<NllLossBackward0>), tensor(0.96))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee0c26-af43-4e1e-966c-c55ab8e7f96a",
   "metadata": {},
   "source": [
    "#### Automatic generation of batchsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "54c4a593-471e-49fb-8f31-49457bb21733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d46eaa-cce3-467d-818d-ae71d9a3d117",
   "metadata": {},
   "source": [
    "#### Automatic generation of random and sequential sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9069cf8d-172f-4b2e-bd95-04e3f7d41cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0036c4d7-aad6-42be-9439-2a4e37ff6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "09f31c80-deaa-4941-ab41-1fe6947a3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21, 0.92\n",
      "0.15, 0.94\n",
      "0.05, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.07, grad_fn=<NllLossBackward0>), tensor(0.96))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2ca39-3c6e-438f-98c1-929b02f2861c",
   "metadata": {},
   "source": [
    "Our dataset actually already knows how to sample a batch of indices all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6174ef3c-a0c8-42eb-b24b-74448022e21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 3]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3990554-7afd-4007-935b-4108f3ca0672",
   "metadata": {},
   "source": [
    "...that means that we can actually skip the batch_sampler and collate_fn entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5be41df2-bb1f-4721-841d-aecbb6d82a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2636b019-e429-4be7-8952-74270861dd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc292b0-1b11-4cab-b590-53f8ac3939b6",
   "metadata": {},
   "source": [
    "## Validation\n",
    "You always should also have a validation set, in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "25a9cf64-ea0c-4daf-9ebc-df2455d6f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count= 0., 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(preds, yb).item() * n\n",
    "                tot_acc += accuracy(pred, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a8c35d98-64c8-48eb-bcc5-0d41fd493478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cab0a5a2-5ed8-4a75-9fa9-bf50dd14f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7fa1020b-36dd-4577-a014-d83e35f8eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.298286051750184 0.958100000321865\n",
      "1 11.298286051750184 0.9631999990344048\n",
      "2 11.298286051750184 0.96450000166893\n",
      "3 11.298286051750184 0.9670000004768372\n",
      "4 11.298286051750184 0.9678000006079673\n",
      "CPU times: user 9.96 s, sys: 7.33 s, total: 17.3 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%time loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0521655-512b-4fa5-93fe-f6e6f2dcd506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153e857f-032c-46c9-bc8c-56a06c9ef3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a90a4cb-ac18-4ac0-815e-05a1436e6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b0b309-14f7-4415-b901-2fa1ab156636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fbabd8-9b9b-4704-9864-af9c954a208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d16ec68-c247-4efa-9cc2-65fb0a462411",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6b603-241a-4e5c-b76a-e8ea1b82e6d6",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d55a76-15ee-491c-97ca-33d52ee38cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1221dcd-1d30-47d3-bc9e-511d4b43d9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10), 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh=50\n",
    "n,m,c, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743a82ae-9130-4ad0-b0c1-5306b1ff84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb4bfb9-76e0-4648-b73d-9a51a710f4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.09, -0.21, -0.08,  ..., -0.03,  0.01,  0.06],\n",
       "        [-0.07, -0.14, -0.14,  ...,  0.03,  0.04,  0.14],\n",
       "        [-0.19, -0.04,  0.02,  ..., -0.01, -0.00,  0.02],\n",
       "        ...,\n",
       "        [-0.03, -0.22, -0.04,  ..., -0.01,  0.09,  0.14],\n",
       "        [-0.10, -0.09, -0.05,  ..., -0.01,  0.02,  0.11],\n",
       "        [-0.03, -0.25, -0.06,  ...,  0.00,  0.03,  0.14]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516cb400-0303-4cca-bf92-da44f8d5f496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623b63b1-a7fe-4ec8-9b57-39023bd2a618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9dbb3fe-7608-4f94-b509-dd55fffeb443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0da918b-0f67-4d7c-8b24-e88a28751a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
       "        3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb861dd-2419-4f1b-95de-75930efbb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7aacb0-c056-453b-a2fb-06593d21d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "302c60a7-1a46-4a0e-8904-97d5f9aa5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f10aa5fb-8f61-489f-b6b1-ef75d4e3a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c09602-1540-4450-b87c-11d1839ccac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.12, 0.94\n",
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc0b11-ca0a-4c06-b793-ffc01135e630",
   "metadata": {},
   "source": [
    "## Using parameters and Optim\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7c9399e-81b2-4e7c-9949-066464df8793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1fab30f-56d1-4f2d-a5fe-c9c7d3282108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.named_children at 0x7f74cd5319a0>,\n",
       " [('foo', Linear(in_features=3, out_features=4, bias=True))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children(), list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c67063e5-4872-4898-8141-18b2f7a803e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0643ed5-b603-4051-827e-dd0a6df2d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31465bb6-9f24-4107-9fd1-d8cd9744278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d283fb-02e6-4701-92a2-9d0424e08e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ff1df4-ad20-40f5-afa5-62536000de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f'{name}: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c09f858-3a60-4a0f-9239-542127d5b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79320369-62b2-4153-adfb-bc8d61802cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70257727-49e5-4f7c-b6a7-d0a428afa247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, 0.96\n",
      "0.11, 0.96\n",
      "0.04, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27d436-602c-428b-8120-24f69c87e31b",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68d6320e-8378-4fc9-b7fd-3acb6c469425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()     # [Equivalent] for p in l.parameters: yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65ccb555-7bd6-4a97-b024-566d75975d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa340a07-2fe6-4dc5-8d73-b6860fa9fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74eabb-2959-4a00-afd2-18b735008e85",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa3fee44-a24e-4446-b387-3f87d58f25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2baac-0f39-4a86-b433-eb8e6f31f815",
   "metadata": {},
   "source": [
    "We can use the orignal `layers` approach, byt we have to register the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85fc0277-1f84-40df-aad0-24c3c0f8574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c4787e0-5716-4835-81ed-45ffe8a7e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        # add__module method is used for making pytorch acknowledge the layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "\n",
    "    def forward(self, x): return reduce(lambda val,layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a5b2779-6ff8-4298-9206-ef404bf4d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13970a04-5c89-4adc-b7e2-d6570964d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9733769-db10-4d3e-8606-f58662f6aadf",
   "metadata": {},
   "source": [
    "## nn.ModuleList\n",
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c5f92b4-c17c-4245-bc5d-36eebe21a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        # Module list performs add_module method over list of layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58fe934d-0d1c-478f-aa64-35624e446fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3eb1d42d-863a-4282-a95a-ec729d827478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.11, 0.96\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a26a9-ba3d-4735-8d1f-e0484391fb43",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "It is a pytorch class which performs the above feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23fa6fb-2c93-46c3-b2c8-c50645ab58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bbc096a-6760-400c-a166-d6ecd74fe758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15, 0.96\n",
      "0.11, 0.96\n",
      "0.09, 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07f6d754-744f-48e8-98cb-206ca067eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd483273-0e51-4e7c-b382-fec845ae4d7c",
   "metadata": {},
   "source": [
    "## optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd601336-9cb6-4ec8-90e5-849a1ddbd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params, self.lr = list(params), lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7d03a77-c11a-4eae-8713-64f6dfc25554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97cacc5f-910e-4c53-87a0-27b766f3b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae523ab9-0ccb-4bbf-a0aa-e03ff9314bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11eb0f8d-b3e9-42c8-8946-4504a3d02e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18, 0.94\n",
      "0.13, 0.96\n",
      "0.11, 0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f63d43-4946-471f-ae48-140f5230b4f6",
   "metadata": {},
   "source": [
    "Pytorch provides exact same functionality with optim.SGD. It also handles momentum which we'll look later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bc607fb-a813-490e-808f-5f834f5195e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a0629d6-664c-488d-b736-e8b36c1546fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfccbc2b-5f4a-4574-b8a3-dc9b40e4723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.33, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "504f4158-4275-42c1-a809-97b20e0eec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.09, 0.98\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757f303-defb-420e-8b66-587e3e930e73",
   "metadata": {},
   "source": [
    "### Dataset & Dataloaders\n",
    "Dataset\n",
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "Instead, let's do these two steps together, by introducing a Dataset class:\n",
    "\n",
    "xb,yb = train_ds[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31812098-7f85-4e30-8d67-60d77a94c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5672930-89e9-4321-94b6-1dcfe033f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b70ef3eb-278a-4711-a9e4-42f22073bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6f9f335-22b1-437b-b21c-ecf4caeb597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2d9e050-59f6-46b9-8261-99243d73b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17, 0.96\n",
      "0.11, 0.94\n",
      "0.09, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = train_ds[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c61c6-8faa-4230-9159-b893a632e3fc",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "```python\n",
    "for i in range(0, n, bs):\n",
    "    xb,yb = train_ds[i:min(n,i+bs)]\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's make our loop much cleaner, using a data loader:\\n,\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3bf8cd1-97e5-47e3-9507-4a8597307107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i: i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd21f796-8721-438a-9471-798baa28afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2724632b-6242-4b11-a208-7654a25a6081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cca8807a-c5da-44c0-97b7-b7ee06d54f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35720e36-4d0c-4544-989b-c00defa82109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d39ea990-47fe-4cf1-8676-449a3aef1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc196b8c-00e7-41e6-a6f6-cdb3fb41f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.98\n",
      "0.09, 0.98\n",
      "0.06, 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.16, grad_fn=<NllLossBackward0>), tensor(0.96))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f10f6-a70f-45bb-8902-1f16ed523495",
   "metadata": {},
   "source": [
    "## Random Sampling \n",
    "We want our training set to be in a random order, and that order should be differ each iteraction. But the validation set shouldn't be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e9152ad-e17c-4195-a091-3d971f86ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11de5378-5512-49f9-91e4-d0ef16837d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e52835a-577f-4bc1-a067-c2656a922f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c7175d7-888b-43c7-af59-ba2cd3e30dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9428daa7-ddd6-4a58-8ef5-f4af21d38a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for o in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e48e9b2-6a3d-4f4f-8310-af57cdcd5635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87304903-d3db-46cf-9c95-fa2977315678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29514, 4989, 30672, 9154, 6400]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c29df93e-ee79-4e12-888e-467eafcd531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1d76ed7-36fd-4e7d-ae79-e11eb3b53d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b943e4d-3d2a-4d95-9346-e8243220db1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6954, 29540, 39446, 7727],\n",
       " [44116, 48010, 9656, 36688],\n",
       " [6829, 4606, 11492, 29492],\n",
       " [25810, 41040, 10302, 39223],\n",
       " [14991, 9516, 25680, 22961]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfb18c03-fa3e-4a66-9352-bcb7cce45c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aee266e8-4102-4749-987a-b8722c854ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdb182d0-0f1d-4fda-b273-8c8a20f87fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "075c5460-57da-4a55-b69c-654411df8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdad8c0e-b71a-4c33-ac77-27b0f65f76a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7e6efca-432c-4577-805c-f351278bb754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b77e7aab-c959-449d-8e9b-4a2e96153ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14, 0.96\n",
      "0.27, 0.92\n",
      "0.21, 0.92\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e76f2-67b4-4b9d-8885-dbf1947b215b",
   "metadata": {},
   "source": [
    "## Multiprocessing Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f6ed588-fec6-4daa-9eed-43057c323e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59583268-e155-44d3-809c-8e50a5c81519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b90b4288-77cc-420b-a5a8-dfd9bab30098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df12d249-50c7-43eb-9554-464cdc8e8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "babbd36c-c98d-4eac-9dc3-6a85d79e69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex:\n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "880a337d-9041-450b-b0bb-fa38b22e2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7ff6fab-11a7-471c-8520-e50845daddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/agastya/mambaforge/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    }
   ],
   "source": [
    "xb, yb= next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b5272-4d84-4403-8841-a70f3bcecefd",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b282e281-4fb8-409b-b7bd-eef27d294915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b94bf28c-dc00-4839-838c-32e17a618b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d0bd169-4393-4490-8c45-289c807ad832",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn = collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3301d6ef-8905-4ebb-a0f4-10f835038b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.96\n",
      "0.11, 0.96\n",
      "0.25, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.02, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee0c26-af43-4e1e-966c-c55ab8e7f96a",
   "metadata": {},
   "source": [
    "#### Automatic generation of batchsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54c4a593-471e-49fb-8f31-49457bb21733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d46eaa-cce3-467d-818d-ae71d9a3d117",
   "metadata": {},
   "source": [
    "#### Automatic generation of random and sequential sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9069cf8d-172f-4b2e-bd95-04e3f7d41cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0036c4d7-aad6-42be-9439-2a4e37ff6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09f31c80-deaa-4941-ab41-1fe6947a3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21, 0.92\n",
      "0.15, 0.94\n",
      "0.05, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.04, grad_fn=<NllLossBackward0>), tensor(0.98))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2ca39-3c6e-438f-98c1-929b02f2861c",
   "metadata": {},
   "source": [
    "Our dataset actually already knows how to sample a batch of indices all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6174ef3c-a0c8-42eb-b24b-74448022e21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 3]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3990554-7afd-4007-935b-4108f3ca0672",
   "metadata": {},
   "source": [
    "...that means that we can actually skip the batch_sampler and collate_fn entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5be41df2-bb1f-4721-841d-aecbb6d82a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2636b019-e429-4be7-8952-74270861dd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc292b0-1b11-4cab-b590-53f8ac3939b6",
   "metadata": {},
   "source": [
    "## Validation\n",
    "You always should also have a validation set, in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "25a9cf64-ea0c-4daf-9ebc-df2455d6f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count= 0., 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                preds = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(preds, yb).item() * n\n",
    "                tot_acc += accuracy(preds, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8c35d98-64c8-48eb-bcc5-0d41fd493478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cab0a5a2-5ed8-4a75-9fa9-bf50dd14f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7fa1020b-36dd-4577-a014-d83e35f8eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.298286051750184 0.958100000321865\n",
      "1 11.298286051750184 0.9631999990344048\n",
      "2 11.298286051750184 0.96450000166893\n",
      "3 11.298286051750184 0.9670000004768372\n",
      "4 11.298286051750184 0.9678000006079673\n",
      "CPU times: user 12 s, sys: 9.54 s, total: 21.6 s\n",
      "Wall time: 5.39 s\n"
     ]
    }
   ],
   "source": [
    "%time loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf23a2-ce1a-44ad-a31b-31669f4e6634",
   "metadata": {},
   "source": [
    "#### Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b769117c-cf84-4346-a805-36adb73f65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048ba8b-a64a-46c2-8c46-97988e13607e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
